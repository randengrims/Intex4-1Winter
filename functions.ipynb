{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49384ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate Stats\n",
    "def unistats(df):\n",
    "    import pandas as pd\n",
    "\n",
    "    output_df = pd.DataFrame(columns=['Count', 'Unique', 'Type', 'Min', 'Max', '25%', '50%', '75%', 'Mean', 'Median', 'Mode', 'Std', 'Skew', 'Kurt'])\n",
    "\n",
    "    for col in df.columns:\n",
    "        # these are the outputs that apply to every variable regardless of data type\n",
    "        count = df[col].count()\n",
    "        unique = df[col].nunique()\n",
    "        dtype = str(df[col].dtype)\n",
    "    \n",
    "    if pd.api.types.is_numeric_dtype(dtype):\n",
    "        # perform additional calculations for numeric variables\n",
    "        min = round(df[col].min(), 2)\n",
    "        max = round(df[col].max(), 2)\n",
    "        quar_1 = round(df[col].quantile(.25), 2)\n",
    "        quar_2 = round(df[col].quantile(.50), 2)\n",
    "        quar_3 = round(df[col].quantile(.75), 2)\n",
    "        mean = round(df[col].mean(), 2)\n",
    "        median = round(df[col].median(), 2)\n",
    "        mode = round(df[col].mode().values[0], 2)  # Use the .values[0] to prevent the return of an extra printed datatype\n",
    "        std = round(df[col].std(), 2) \n",
    "        skew = round(df[col].skew(), 2)\n",
    "        kurt = round(df[col].kurt(), 2)\n",
    "\n",
    "        output_df.loc[col] = (count, unique, dtype, min, max, quar_1, quar_2, quar_3, mean, median, mode, std, skew, kurt)\n",
    "    else:\n",
    "        output_df.loc[col] = (count, unique, dtype, '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-')\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab61275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binning Categorical features\n",
    "def bin_categories(df, features=[], cutoff=0.05, replace_with='Other', messages=True):\n",
    "        import pandas as pd  # Import pandas for DataFrame operations\n",
    "    \n",
    "        # Loop through each specified feature\n",
    "        for feat in features:\n",
    "          if feat in df.columns:  # Check if the feature exists in the DataFrame\n",
    "            if not pd.api.types.is_numeric_dtype(df[feat]):  # Ensure the feature is categorical\n",
    "              # Identify categories that appear in less than 'cutoff' proportion of the dataset\n",
    "              other_list = df[feat].value_counts()[df[feat].value_counts() / df.shape[0] < cutoff].index\n",
    "    \n",
    "              # Replace rare categories with the specified label (default: \"Other\")\n",
    "              df.loc[df[feat].isin(other_list), feat] = replace_with\n",
    "          else:\n",
    "            if messages: \n",
    "              print(f'{feat} not found in the DataFrame provided. No binning performed')  # Warn if feature is missing\n",
    "    \n",
    "        return df  # Return the modified DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f468f20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_drop(df, label=\"\", features=[], messages=True, row_threshold=.9, col_threshold=.5):\n",
    "    import pandas as pd\n",
    "    \n",
    "    start_count = df.count().sum()  # Store the initial count of non-null values\n",
    "    \n",
    "    # Drop columns with missing values beyond the specified column threshold\n",
    "    df.dropna(axis=1, thresh=round(col_threshold * df.shape[0]), inplace=True)\n",
    "    # Drop rows that have fewer non-null values than the row threshold allows\n",
    "    df.dropna(axis=0, thresh=round(row_threshold * df.shape[1]), inplace=True)\n",
    "    # If a label is specified, ensure it has no missing values\n",
    "    if label != \"\": \n",
    "        df.dropna(axis=0, subset=[label], inplace=True)\n",
    "    \n",
    "    # Function to generate a summary of missing data for each column\n",
    "    def generate_missing_table():\n",
    "        df_results = pd.DataFrame(columns=['Missing', 'column', 'rows'])\n",
    "        for feat in df:\n",
    "            missing = df[feat].isna().sum()  # Count missing values in column\n",
    "            if missing < 0:\n",
    "                memory_col = df.drop(columns=[feat]).count().sum()  # Count non-null values if this column is dropped\n",
    "                memory_rows = df.dropna(subset=[feat]).count().sum()  # Count non-null values if this column is kept\n",
    "                df_results.loc[feat] = [missing, memory_col, memory_rows]  # Store results\n",
    "        return df_results\n",
    "    \n",
    "    df_results = generate_missing_table()  # Generate initial missing data table\n",
    "    \n",
    "    # Iteratively remove the column or row that preserves the most non-null data\n",
    "    while df_results.shape[0] > 0:\n",
    "        max = df_results[['column', 'rows']].max(axis=1)[0]  # Find the max value in columns or rows\n",
    "        max_axis = df_results.columns[df_results.isin([max]).any()][0]  # Determine whether to drop column or row\n",
    "        print(max, max_axis)\n",
    "    \n",
    "        df_results.sort_values(by=[max_axis], ascending=False, inplace=True)  # Sort missing data table by max_axis\n",
    "        if messages: print('\\n', df_results)\n",
    "    \n",
    "        # Drop the most impactful missing data (either row or column)\n",
    "        if max_axis == 'rows':\n",
    "            df.dropna(axis=0, subset=[df_results.index[0]], inplace=True)  # Drop row with highest missing impact\n",
    "        else:\n",
    "            df.drop(columns=[df_results.index[0]], inplace=True)  # Drop column with highest missing impact\n",
    "    \n",
    "        df_results = generate_missing_table()  # Recalculate missing data table after dropping\n",
    "    \n",
    "    # Print the percentage of non-null values retained\n",
    "    if messages: \n",
    "        print(f'{round(df.count().sum() / start_count * 100, 2)}% ({df.count().sum()}) / ({start_count}) of non-null cells were kept.')\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a05005d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric to Numeric\n",
    "# age vs. rating (after joining movies_users and movies_ratings)\n",
    "# release_year vs. average rating (from movies_titles and movies_ratings)\n",
    "\n",
    "# REMINDER: USE SCATTER PLOTS, CORRELATION COEFFICIENTS\n",
    "def bivariate_stats(df, label, roundto=4):\n",
    "    import pandas as pd\n",
    "    from scipy import stats\n",
    "        \n",
    "    output_df = pd.DataFrame(columns=['p', 'r', 'y = m(x) + b'])\n",
    "    \n",
    "    for feature in df.columns:\n",
    "        if feature != label: # No need to calculate the relationship of the label with itself\n",
    "            if pd.api.types.is_numeric_dtype(df[feature]):\n",
    "                m, b, r, p, err = stats.linregress(df[feature], df[label]) # Calculate the regression line\n",
    "                output_df.loc[feature] = [round(p, roundto), round(r, roundto), f'y = {round(m, roundto)}(x) + {round(b, roundto)}']\n",
    "    \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6000e39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SCATTER PLOT\n",
    "def scatterplot(df, feature, label, roundto=3, linecolor='darkorange'):\n",
    "    import pandas as pd\n",
    "    from matplotlib import pyplot as plt\n",
    "    import seaborn as sns\n",
    "    from scipy import stats\n",
    "    \n",
    "    # Create a scatter plot with a regression line\n",
    "    sns.regplot(x=df[feature], y=df[label], line_kws={\"color\": linecolor})\n",
    "    \n",
    "    # Perform linear regression to calculate regression statistics\n",
    "    m, b, r, p, err = stats.linregress(df[feature], df[label])\n",
    "    \n",
    "    # Format the regression equation and statistics into a text string\n",
    "    textstr  = 'Regression line:' + '\\n'\n",
    "    textstr += 'y  = ' + str(round(m, roundto)) + 'x + ' + str(round(b, roundto)) + '\\n'\n",
    "    textstr += 'r   = ' + str(round(r, roundto)) + '\\n'  # Pearson correlation coefficient\n",
    "    textstr += 'r²  = ' + str(round(r**2, roundto)) + '\\n'  # Coefficient of determination (R-squared)\n",
    "    textstr += 'p  = ' + str(round(p, roundto)) + '\\n\\n'  # P-value indicating significance\n",
    "    \n",
    "    # Display the regression statistics on the plot\n",
    "    plt.text(1, 0.1, textstr, fontsize=12, transform=plt.gcf().transFigure)\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df4fc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical to Numeric\n",
    "# Average rating by type (Movie vs. TV Show)\n",
    "# Average age by gender\n",
    "# Number of users by streaming platform (e.g., Netflix = 0/1)\n",
    "\n",
    "# REMINDER: USE BOX PLOTS, BAR PLOTS\n",
    "def bivariate_stats(df, label, roundto=4):\n",
    "      import pandas as pd\n",
    "      from scipy import stats\n",
    "      \n",
    "      output_df = pd.DataFrame(columns=['missing', 'p', 'r', 'y = m(x) + b', 'F'])\n",
    "      \n",
    "      for feature in df.columns:\n",
    "        if feature != label:\n",
    "          df_temp = df[[feature, label]]\n",
    "          df_temp = df_temp.dropna()\n",
    "          missing = (df.shape[0] - df_temp.shape[0]) / df.shape[0] # Calculate the percent of rows missing if either the feature or label are missing\n",
    "      \n",
    "          if pd.api.types.is_numeric_dtype(df[feature]) and pd.api.types.is_numeric_dtype(df[label]):\n",
    "            m, b, r, p, err = stats.linregress(df_temp[feature], df_temp[label])\n",
    "            output_df.loc[feature] = [f'{missing:.2%}', 'r', round(r, roundto), round(p, roundto), f'y = {round(m, roundto)}(x) + {round(b, roundto)}', '-']\n",
    "          \n",
    "          elif not pd.api.types.is_numeric_dtype(df_temp[feature]) and not pd.api.types.is_numeric_dtype(df[label]):\n",
    "            output_df.loc[feature] = [f'{missing:.2%}', '-', '-', '-', '-']\n",
    "          \n",
    "          else:\n",
    "            if pd.api.types.is_numeric_dtype(df_temp[feature]): \n",
    "              num = feature\n",
    "              cat = label\n",
    "            else:\n",
    "              num = label\n",
    "              cat = feature\n",
    "            \n",
    "            groups = df_temp[cat].unique()\n",
    "            group_lists = []\n",
    "            for g in groups:\n",
    "              g_list = df_temp[df_temp[cat] == g][num]\n",
    "              group_lists.append(g_list)\n",
    "      \n",
    "            results = stats.f_oneway(*group_lists)\n",
    "            F = results[0]\n",
    "            p = results[1]\n",
    "            output_df.loc[feature] = [f'{missing:.2%}', round(p, roundto), '-', '-', round(F, roundto)]\n",
    "      return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcaab5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (736788134.py, line 45)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[16], line 45\u001b[1;36m\u001b[0m\n\u001b[1;33m    if ttest[2] lt;= p_threshold:  # If p-value is below Bonferroni threshold\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def bar_chart(df, feature, label, roundto=3):\n",
    "        import pandas as pd\n",
    "        from scipy import stats\n",
    "        from matplotlib import pyplot as plt\n",
    "        import seaborn as sns\n",
    "        \n",
    "        # Create a bar chart displaying the mean of the label for each category in the feature\n",
    "        sns.barplot(df, x=feature, y=label)\n",
    "        \n",
    "        # Perform one-way ANOVA (F-test) to compare means of different groups in the categorical feature\n",
    "        groups = df[feature].unique()  # Get unique categories of the feature\n",
    "        group_lists = []\n",
    "        \n",
    "        # Create a list of values for each group\n",
    "        for g in groups:\n",
    "          g_list = df[df[feature] == g][label]\n",
    "          group_lists.append(g_list)\n",
    "        \n",
    "        results = stats.f_oneway(*group_lists)  # Conduct ANOVA test\n",
    "        F = results[0]  # Extract the F-statistic\n",
    "        p = results[1]  # Extract the p-value\n",
    "        \n",
    "        # Conduct pairwise t-tests with Bonferroni correction\n",
    "        ttests = []  # Store significant t-test results\n",
    "        for i1, g1 in enumerate(groups):\n",
    "          for i2, g2 in enumerate(groups):\n",
    "            if i2 > i1:  # Compare each unique pair once\n",
    "              type_1 = df[df[feature] == g1]\n",
    "              type_2 = df[df[feature] == g2]\n",
    "              t, p = stats.ttest_ind(type_1[label], type_2[label])  # Perform independent t-test\n",
    "        \n",
    "              # Store the results\n",
    "              ttests.append([str(g1) + ' - ' + str(g2), round(t, roundto), round(p, roundto)])\n",
    "        \n",
    "        # Compute Bonferroni-corrected p-value threshold\n",
    "        p_threshold = 0.05 / len(ttests)\n",
    "        \n",
    "        # Create annotation text for the plot\n",
    "        textstr  = '   ANOVA' + '\\n'\n",
    "        textstr += 'F: ' + str(round(F, roundto)) + '\\n'\n",
    "        textstr += 'p: ' + str(round(p, roundto)) + '\\n\\n'\n",
    "        \n",
    "        # Add only significant t-test results\n",
    "        for ttest in ttests:\n",
    "            if ttest[2] lt;= p_threshold:  # If p-value is below Bonferroni threshold\n",
    "                if 'Sig. comparisons (Bonferroni-corrected)' not in textstr:\n",
    "                    textstr += 'Sig. comparisons (Bonferroni-corrected)' + '\\n'\n",
    "                textstr += str(ttest[0]) + \": t=\" + str(ttest[1]) + \", p=\" + str(ttest[2]) + '\\n'\n",
    "       \n",
    "        # Display statistical results as text on the chart\n",
    "        plt.text(1, 0.1, textstr, fontsize=12, transform=plt.gcf().transFigure)\n",
    "        \n",
    "        # Show the plot\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c34fe3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical to Categorical \n",
    "\n",
    "#type vs. rating categories\n",
    "# gender vs. platform subscriptions\n",
    "# Genre (binary flags) vs. country\n",
    "\n",
    "# REMINDER: USE CHI-SQURE TEST, CROSS-TAB\n",
    "def bivariate_stats(df, label, roundto=4):\n",
    "        import pandas as pd\n",
    "        from scipy import stats  # Import statistical tests from scipy\n",
    "          \n",
    "        # Initialize an empty DataFrame to store the output\n",
    "        output_df = pd.DataFrame(columns=['missing', 'p', 'r', 'y = m(x) + b', 'F', 'X2'])\n",
    "        \n",
    "        # Iterate through all columns in the DataFrame\n",
    "        for feature in df.columns:\n",
    "          if feature != label:  # Ensure we do not process the label column itself\n",
    "            df_temp = df[[feature, label]].dropna()  # Drop rows with missing values for feature and label\n",
    "            missing = (df.shape[0] - df_temp.shape[0]) / df.shape[0]  # Calculate the proportion of missing values\n",
    "        \n",
    "            # Case 1: Both feature and label are numeric (Continuous vs Continuous)\n",
    "            if pd.api.types.is_numeric_dtype(df_temp[feature]) and pd.api.types.is_numeric_dtype(df_temp[label]):\n",
    "              # Perform linear regression\n",
    "              m, b, r, p, err = stats.linregress(df_temp[feature], df_temp[label])\n",
    "              # Store results in output DataFrame\n",
    "              output_df.loc[feature] = [\n",
    "                f'{missing:.2%}',  # Percentage of missing values\n",
    "                round(p, roundto),  # P-value of regression\n",
    "                round(r, roundto),  # Pearson correlation coefficient\n",
    "                f'y = {round(m, roundto)}(x) + {round(b, roundto)}',  # Regression equation\n",
    "                '-', '-'  # Not applicable for F-test or Chi-square test\n",
    "              ]\n",
    "        \n",
    "            # Case 2: Both feature and label are categorical (Categorical vs Categorical)\n",
    "            elif not pd.api.types.is_numeric_dtype(df_temp[feature]) and not pd.api.types.is_numeric_dtype(df_temp[label]):\n",
    "              # Create a contingency table (cross-tabulation)\n",
    "              contingency_table = pd.crosstab(df_temp[feature], df_temp[label])\n",
    "              # Perform Chi-square test for independence\n",
    "              X2, p, dof, expected = stats.chi2_contingency(contingency_table)\n",
    "              # Store results in output DataFrame\n",
    "              output_df.loc[feature] = [\n",
    "                f'{missing:.2%}',  # Percentage of missing values\n",
    "                round(p, roundto),  # P-value from Chi-square test\n",
    "                '-', '-', '-',  # Not applicable for regression or F-test\n",
    "                round(X2, roundto)  # Chi-square test statistic\n",
    "              ]\n",
    "                \n",
    "            # Case 3: One variable is categorical, the other is numeric (Categorical vs Continuous)\n",
    "            else:\n",
    "              # Identify which variable is numeric and which is categorical\n",
    "              if pd.api.types.is_numeric_dtype(df_temp[feature]): \n",
    "                num = feature  # Numeric variable\n",
    "                cat = label  # Categorical variable\n",
    "              else:\n",
    "                num = label\n",
    "                cat = feature\n",
    "              \n",
    "              # Extract unique categories\n",
    "              groups = df_temp[cat].unique()\n",
    "              group_lists = []\n",
    "      \n",
    "              # Create a list of values for each group\n",
    "              for g in groups:\n",
    "                g_list = df_temp[df_temp[cat] == g][num]\n",
    "                group_lists.append(g_list)\n",
    "      \n",
    "              # Perform one-way ANOVA (F-test) to compare group means\n",
    "              results = stats.f_oneway(*group_lists)\n",
    "              F = results[0]  # F-statistic\n",
    "              p = results[1]  # P-value\n",
    "      \n",
    "              # Store results in output DataFrame\n",
    "              output_df.loc[feature] = [\n",
    "                f'{missing:.2%}',  # Percentage of missing values\n",
    "                round(p, roundto),  # P-value from ANOVA\n",
    "                '-', '-',  # Not applicable for regression or Chi-square\n",
    "                round(F, roundto), '-'  # F-test statistic, Chi-square not applicable\n",
    "              ]\n",
    "      \n",
    "        # Return the output DataFrame, sorted by p-value (smallest first)\n",
    "        return output_df.sort_values(by=['p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1a5d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crosstab(df, feature, label, roundto=3):\n",
    "    import pandas as pd\n",
    "    from scipy.stats import chi2_contingency\n",
    "    from matplotlib import pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import numpy as np\n",
    "    \n",
    "    # Handle missing data: Remove rows where either feature or label has missing values\n",
    "    df_temp = df[[feature, label]].dropna()\n",
    "    \n",
    "    # Bin categories if needed (consolidate rare categories into \"Other\")\n",
    "    df_temp = bin_categories(df_temp, feature)\n",
    "    \n",
    "    # Generate the contingency table (crosstab)\n",
    "    crosstab = pd.crosstab(df_temp[feature], df_temp[label])\n",
    "    \n",
    "    # Perform Chi-square test of independence\n",
    "    X, p, dof, contingency_table = chi2_contingency(crosstab)\n",
    "    \n",
    "    # Format the test results into a text string\n",
    "    textstr  = 'X²: ' + str(round(X, roundto)) + '\\n'\n",
    "    textstr += 'p = ' + str(round(p, roundto)) + '\\n'\n",
    "    textstr += 'dof = ' + str(dof)\n",
    "    \n",
    "    # Display the test results on the plot\n",
    "    plt.text(0.9, 0.1, textstr, fontsize=12, transform=plt.gcf().transFigure)\n",
    "    \n",
    "    # Convert expected frequencies to a DataFrame with rounded integer values\n",
    "    ct_df = pd.DataFrame(np.rint(contingency_table).astype('int64'), columns=crosstab.columns, index=crosstab.index)\n",
    "    \n",
    "    # Create a heatmap visualization of the contingency table\n",
    "    sns.heatmap(ct_df, annot=True, fmt='d', cmap='coolwarm')\n",
    "    \n",
    "    # Show the heatmap\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280e1890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate(df, sample=500):\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    import math\n",
    "    \n",
    "    df_results = pd.DataFrame(columns=['bin_groups', 'type', 'missing', 'unique', 'min',\n",
    "                                        'median', 'max', 'mode', 'mean', 'std', 'skew'])\n",
    "    \n",
    "    for col in df:\n",
    "        # Features that apply to all dtypes\n",
    "        dtype = df[col].dtype\n",
    "        missing = df[col].isna().sum()\n",
    "        unique = df[col].nunique()\n",
    "        mode = df[col].mode()[0]\n",
    "        if pd.api.types.is_numeric_dtype(df[col]):\n",
    "        # Features for numeric dtypes only\n",
    "            min = df[col].min()\n",
    "            max = df[col].max()\n",
    "            mean = df[col].mean()\n",
    "            median = df[col].median()\n",
    "            std = df[col].std()\n",
    "            skew = df[col].skew()\n",
    "            df_results.loc[col] = ['-', dtype, missing, unique, min, median, max, mode,\n",
    "                                    round(mean, 2), round(std, 2), round(skew, 2)]\n",
    "        else:\n",
    "            # Features for object dtypes only\n",
    "            flag = df[col].value_counts()[(df[col].value_counts() / df.shape[0]) < 0.05].shape[0]\n",
    "            df_results.loc[col] = [flag, dtype, missing, unique, '-', '-', '-', mode, '-', '-', '-']\n",
    "    \n",
    "    # Make a sub-DataFrame of features that are objects or have only two values; they will need countplots\n",
    "    countplots = df_results[(df_results['type']=='object') | (df_results['unique']==2)]\n",
    "    # Make a sub-DataFrame of features that are floats or ints with many values which will need histograms\n",
    "    histograms = df_results[(df_results['type']=='float64') | ((df_results['unique']>10) & (df_results['type']=='int64'))]\n",
    "    histograms = histograms[histograms['unique']>2] # Remove those that are binary\n",
    "    \n",
    "    # Create a set of countplots for the categorical features\n",
    "    f, ax = plt.subplots(1, countplots.shape[0], figsize=[countplots.shape[0] * 1.5, 1.5])\n",
    "    for i, col in enumerate(countplots.index):\n",
    "        g = sns.countplot(data=df, x=col, color='g', ax=ax[i]);\n",
    "        g.set_yticklabels('')\n",
    "        g.set_ylabel('')\n",
    "        ax[i].tick_params(labelrotation=90, left=False)\n",
    "        ax[i].xaxis.set_label_position('top')\n",
    "        sns.despine(left=True, top=True, right=True)\n",
    "    \n",
    "    plt.subplots_adjust(hspace=2, wspace=.5)\n",
    "    plt.show()\n",
    "    \n",
    "    # Create a set of histograms for the numeric features\n",
    "    f, ax = plt.subplots(1, histograms.shape[0], figsize=[histograms.shape[0] * 1.5, 1.5])\n",
    "    for i, col in enumerate(histograms.index):\n",
    "        g = sns.histplot(data=df.sample(n=sample, random_state=1), x=col, color='b', ax=ax[i], kde=True);\n",
    "        g.set_yticklabels(labels=[])\n",
    "        g.set_ylabel('')\n",
    "        ax[i].tick_params(left=False)\n",
    "        sns.despine(left=True, top=True, right=True)\n",
    "    \n",
    "    plt.subplots_adjust(hspace=2, wspace=.5)\n",
    "    plt.show()\n",
    "    \n",
    "    return df_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
